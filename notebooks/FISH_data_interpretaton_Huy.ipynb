{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FISH - Data interpretation - A Python interactive notebook to interpret FISH data\n",
    "\n",
    "```\n",
    "Author: Luis U. Aguilera\n",
    "Contact Info: luis.aguilera@colostate.edu\n",
    "\n",
    "Copyright (c) 2021 Munsky Group \n",
    "Colorado State University \n",
    "Licensed under BSD 3-Clause License.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook summary \n",
    "\n",
    "\n",
    "- Load a directory with data quantified by FISH_pipeline.ipynb\n",
    "- Establish a connection to Network-attached storage (NAS) using [pysmb](https://github.com/miketeo/pysmb)\n",
    "- Compares quantifications for multiple conditions in a single plot\n",
    "- Compares mRNA spots in the  nucleus, cytosol and the comple cell.\n",
    "  \n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src= /home/luisub/Desktop/FISH_Processing/docs/images/code_architecture.png alt=\"drawing\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import matplotlib.pyplot as plt \n",
    "from  matplotlib.ticker import FuncFormatter\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import warnings\n",
    "import glob\n",
    "import seaborn as sns\n",
    "import zipfile\n",
    "import shutil\n",
    "import scipy.stats as stats\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining directories\n",
    "current_dir = pathlib.Path().absolute()\n",
    "fa_dir = current_dir.parents[0].joinpath('src')\n",
    "# Importing fish_analyses module\n",
    "sys.path.append(str(fa_dir))\n",
    "import fish_analyses as fa\n",
    "# Local folder path\n",
    "local_folder_path = pathlib.Path().absolute().joinpath('temp_zip_analyses')\n",
    "local_folder_path\n",
    "# Path to credentials\n",
    "desktop_path = pathlib.Path.home()/'Desktop'\n",
    "# Connection to munsky-nas\n",
    "path_to_config_file = desktop_path.joinpath('config.yml')\n",
    "share_name = 'share'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of folders to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Huy_60X(mandatory_substring):\n",
    "    list_dirs=(\n",
    "    'smFISH_images/Linda_smFISH_images/Confocal/20220714/MS2-CY5_Cyto543_560_woStim',\n",
    "    'smFISH_images/Linda_smFISH_images/Confocal/20220714/MS2-CY5_Cyto543_560_18minTPL_5uM' ,\n",
    "    'smFISH_images/Linda_smFISH_images/Confocal/20220714/MS2-CY5_Cyto543_560_5hTPL_5uM' )\n",
    "    list_labels = [ 'woSTM','18minTPL_5uM','5hTPL_5uM']\n",
    "    plot_title_suffix= \"MS2_CY5_60X\"\n",
    "    mandatory_substring = mandatory_substring      #'nuc_80__cyto_0__psfz_350__psfyx_160__ts_220'\n",
    "    return list_dirs, list_labels, plot_title_suffix, mandatory_substring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Huy_100X(mandatory_substring):\n",
    "    list_dirs=(\n",
    "    'smFISH_images/Linda_smFISH_images/Confocal/20211014/MS2-CY5-0minTPL',\n",
    "    'smFISH_images/Linda_smFISH_images/Confocal/20211014/MS2-CY5-3minTPL',\n",
    "    'smFISH_images/Linda_smFISH_images/Confocal/20211015/MS2-CY5-6minTPL',\n",
    "    'smFISH_images/Linda_smFISH_images/Confocal/20211015/MS2-CY5-9minTPL', \n",
    "    'smFISH_images/Linda_smFISH_images/Confocal/20211015/MS2-CY5-12minTPL', \n",
    "    'smFISH_images/Linda_smFISH_images/Confocal/20211019/MS2-CY5-15minTPL',\n",
    "    'smFISH_images/Linda_smFISH_images/Confocal/20211019/MS2-CY5-18minTPL', \n",
    "    'smFISH_images/Linda_smFISH_images/Confocal/20211019/MS2-CY5-21minTPL', \n",
    "    'smFISH_images/Linda_smFISH_images/Confocal/20211021/MS2-CY5-24minTPL', \n",
    "    'smFISH_images/Linda_smFISH_images/Confocal/20211021/MS2-CY5-27minTPL', \n",
    "    'smFISH_images/Linda_smFISH_images/Confocal/20211021/MS2-CY5-30minTPL', \n",
    "    'smFISH_images/Linda_smFISH_images/Confocal/20211021/MS2-CY5-60minTPL', \n",
    "    'smFISH_images/Linda_smFISH_images/Confocal/20210921/MS2-Cy5-120minTPL', \n",
    "    'smFISH_images/Linda_smFISH_images/Confocal/20210921/MS2-Cy5-240minTPL' )\n",
    "    list_labels = [ '0min_TPL','3min_TPL','6min_TPL','9min_TPL','12min_TPL','15min_TPL','18min_TPL','21min_TPL','24min_TPL','27min_TPL','30min_TPL','60min_TPL', '120min_TPL','240min_TPL']\n",
    "    plot_title_suffix= \"MS2_CY5_100X\"\n",
    "    mandatory_substring = mandatory_substring      #'nuc_180__cyto_0__psfz_350__psfyx_120__ts_auto'\n",
    "    return list_dirs, list_labels, plot_title_suffix, mandatory_substring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "# Running the codes\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the code please provide the list of folder to process. The code also needs a **mandatory_substring** this string describes the parameters used to generate the data. In short, the string can look like this:  'nuc_80__cyto_200__psfz_350__psfyx_160__ts_220'.\n",
    "\n",
    "and this means:\n",
    "\n",
    "nuc_80    : the size used to segment the nucleus \\\n",
    "cyto_200  : the size used to segment the cytosol \\\n",
    "psfz_350  : the size of the psf in z \\\n",
    "psfyx_160 : the size of the  psf in yx \\\n",
    "ts_220 : a threshold for spot detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To download data from NAS it is necessary to use CSU network or use the CSU VPN.\n",
    "#list_dirs, list_labels, plot_title_suffix, mandatory_substring = Huy_100X(mandatory_substring='nuc_80__cyto_0__psfz_350__psfyx_160__ts_220')\n",
    "list_dirs, list_labels, plot_title_suffix, mandatory_substring = Huy_60X(mandatory_substring='nuc_180__cyto_0__psfz_350__psfyx_120__ts_auto')\n",
    "minimal_TS_size = 3 # Just for the plotting\n",
    "connect_to_NAS = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to NAS and extracting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection established\n",
      "Connection established\n",
      "Connection established\n"
     ]
    }
   ],
   "source": [
    "if connect_to_NAS == True:\n",
    "    # Reading the data from NAS, unziping files, organizing data as single dataframe for comparison. \n",
    "    list_local_files = fa.Utilities.read_zipfiles_from_NAS(list_dirs,path_to_config_file,share_name, mandatory_substring, local_folder_path)\n",
    "    list_local_folders = fa.Utilities.unzip_local_folders(list_local_files,local_folder_path)\n",
    "else: \n",
    "    list_local_folders = list_dirs # Use this line to process files from a local repository\n",
    "# Extracting data from each repository\n",
    "list_spots_total, list_spots_nuc, list_spots_cytosol, list_number_cells, list_transcription_sites,list_cell_size,list_dataframes,list_nuc_size = fa.Utilities.extracting_data_for_each_df_in_directory(  list_local_folders=list_local_folders,current_dir=current_dir,minimal_TS_size=minimal_TS_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of cells in each dataset:  []\n"
     ]
    }
   ],
   "source": [
    "print('number of cells in each dataset: ', list_number_cells)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting Dataframe to use in Brian's Matlab code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting data for Matlab codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "psf_z=350                # Theoretical size of the PSF emitted by a [rna] spot in the z plan, in nanometers\n",
    "psf_yx=160               # Theoretical size of the PSF emitted by a [rna] spot in the yx plan, in nanometers\n",
    "voxel_size_z=500         # Microscope conversion px to nanometers in the z axis.\n",
    "voxel_size_yx=160        # Microscope conversion px to nanometers in the xy axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = np.array ([ voxel_size_z/psf_z, voxel_size_yx/psf_yx, voxel_size_yx/psf_yx ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_spot_classification_from_df(df,threshold_in_pixels=2,show_plots = False):\n",
    "    number_cells = df['cell_id'].nunique()\n",
    "    array_spot_type_per_cell = np.zeros((number_cells, 7)).astype(int) # this array will store the spots separated  as types: spot_0_only, spot_1_only, or spot_0_1\n",
    "    for cell_id in range(number_cells):\n",
    "        # retrieving the coordinates for spots type 0 and 1 for each cell \n",
    "        array_spots_0 = np.asarray( df[['z','y','x']][(df[\"cell_id\"] == cell_id) & (df[\"spot_type\"] == 0)] ) # coordinates for spot_type_0 with shape [num_spots_type_0, 3]\n",
    "        array_spots_1 = np.asarray( df[['z','y','x']][(df[\"cell_id\"] == cell_id) & (df[\"spot_type\"] == 1)] ) # coordinates for spot_type_1 with shape [num_spots_type_1, 3]\n",
    "            \n",
    "        total_spots0 = array_spots_0.shape[0]\n",
    "        total_spots1 = array_spots_1.shape[0]\n",
    "        # Concatenating arrays from spots 0 and 1\n",
    "        array_all_spots = np.concatenate((array_spots_0,array_spots_1), axis=0) \n",
    "        # Calculating a distance matrix. \n",
    "        distance_matrix = np.zeros( (array_all_spots.shape[0], array_all_spots.shape[0])) #  the distance matrix is an square matrix resulting from the concatenation of both spot  types.\n",
    "        for i in range(len(array_all_spots)):\n",
    "            for j in range(len(array_all_spots)):\n",
    "                if j<i:\n",
    "                    distance_matrix[i,j] = np.linalg.norm( ( array_all_spots[i,:]-array_all_spots[j,:] ) * scale )\n",
    "        # masking the distance matrix. Ones indicate the distance is less or equal than threshold_in_pixels\n",
    "        mask_distance_matrix = (distance_matrix <= threshold_in_pixels) \n",
    "        # Selecting the right-lower quadrant as a subsection of the distance matrix that compares one spot type versus the other. \n",
    "        subsection_mask_distance_matrix = mask_distance_matrix[total_spots0:, 0:total_spots0].copy()\n",
    "        if show_plots == True:\n",
    "            plt.imshow(mask_distance_matrix, cmap='Greys_r')\n",
    "            plt.imshow(subsection_mask_distance_matrix,cmap='Greys_r')\n",
    "        # Calculating each type of spots in cell\n",
    "        is_spot_only_type_0 = np.all(~subsection_mask_distance_matrix, axis =1 ) # Testing if all the columns are ones of inv(subsection_mask_distance_matrix). Representing spot type 0.\n",
    "        is_spot_only_type_1 = np.all(~subsection_mask_distance_matrix, axis =0 ) #  Testing if all the rows are ones of inv(subsection_mask_distance_matrix). Representing spot type 1.\n",
    "        num_type_0_only = np.sum(is_spot_only_type_0) \n",
    "        num_type_1_only =np.sum(is_spot_only_type_1) \n",
    "        num_type_0_1 = (total_spots0 - num_type_0_only) + (total_spots1 - num_type_1_only) # Number of spots in both channels\n",
    "        array_spot_type_per_cell[cell_id,:] = np.array([cell_id, num_type_0_only, num_type_1_only, num_type_0_1, num_type_0_only+num_type_0_1, \n",
    "                                                        num_type_1_only+num_type_0_1, num_type_0_only+num_type_1_only+num_type_0_1]).astype(int)\n",
    "        list_labels = ['cell_id','number_spots_type_0','number_spots_type_1','number_spots_type_0_1','munber_0', 'number_1','total']\n",
    "        # creating a dataframe\n",
    "        df_spots_classification = pd.DataFrame(data=array_spot_type_per_cell, columns=list_labels)\n",
    "    return df_spots_classification  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a folder to store all plots\n",
    "destination_folder = pathlib.Path().absolute().joinpath('results', 'data_'+plot_title_suffix+'__'+mandatory_substring)\n",
    "if not os.path.exists(destination_folder):\n",
    "    os.makedirs(destination_folder) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterating for each time point (experimental condition)\n",
    "num_time_points = len(list_dataframes)\n",
    "for i in range(0, num_time_points):\n",
    "    df_spots_classification = extract_spot_classification_from_df(df=list_dataframes[i],threshold_in_pixels=2,show_plots = False)\n",
    "    df_spots_classification.to_csv(pathlib.Path().absolute().joinpath(destination_folder,plot_title_suffix+'_classification_'+'time_'+str(i)+'.csv'))\n",
    "    # saving the  original dataframe  back to the same folder\n",
    "    list_dataframes[i].to_csv(pathlib.Path().absolute().joinpath(destination_folder,plot_title_suffix+'_complete_'+'time_'+str(i)+'.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/luisub/Desktop/FISH_Processing/notebooks/temp_zip_analyses'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/luisub/Desktop/FISH_Processing/notebooks/FISH_data_interpretaton_Huy.ipynb Cell 24\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2253636f74745f4c756973227d/home/luisub/Desktop/FISH_Processing/notebooks/FISH_data_interpretaton_Huy.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# remove temporary folder\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2253636f74745f4c756973227d/home/luisub/Desktop/FISH_Processing/notebooks/FISH_data_interpretaton_Huy.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m shutil\u001b[39m.\u001b[39;49mrmtree(local_folder_path)\n",
      "File \u001b[0;32m~/anaconda3/envs/FISH_processing/lib/python3.8/shutil.py:709\u001b[0m, in \u001b[0;36mrmtree\u001b[0;34m(path, ignore_errors, onerror)\u001b[0m\n\u001b[1;32m    707\u001b[0m     orig_st \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mlstat(path)\n\u001b[1;32m    708\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m--> 709\u001b[0m     onerror(os\u001b[39m.\u001b[39;49mlstat, path, sys\u001b[39m.\u001b[39;49mexc_info())\n\u001b[1;32m    710\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    711\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/FISH_processing/lib/python3.8/shutil.py:707\u001b[0m, in \u001b[0;36mrmtree\u001b[0;34m(path, ignore_errors, onerror)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[39m# Note: To guard against symlink races, we use the standard\u001b[39;00m\n\u001b[1;32m    705\u001b[0m \u001b[39m# lstat()/open()/fstat() trick.\u001b[39;00m\n\u001b[1;32m    706\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 707\u001b[0m     orig_st \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49mlstat(path)\n\u001b[1;32m    708\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    709\u001b[0m     onerror(os\u001b[39m.\u001b[39mlstat, path, sys\u001b[39m.\u001b[39mexc_info())\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/luisub/Desktop/FISH_Processing/notebooks/temp_zip_analyses'"
     ]
    }
   ],
   "source": [
    "# remove temporary folder\n",
    "shutil.rmtree(local_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f123aec772437107f61ad48bdc3e74202fc8f652e2fa44805dd8339e0a72f809"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('FISH_processing')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
