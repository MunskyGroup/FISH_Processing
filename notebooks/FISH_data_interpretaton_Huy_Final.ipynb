{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FISH - Data interpretation - A Python interactive notebook to interpret FISH data\n",
    "\n",
    "```\n",
    "Author: Luis U. Aguilera\n",
    "Contact Info: luis.aguilera@colostate.edu\n",
    "\n",
    "Copyright (c) 2021 Munsky Group \n",
    "Colorado State University \n",
    "Licensed under BSD 3-Clause License.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import matplotlib.pyplot as plt \n",
    "from  matplotlib.ticker import FuncFormatter\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import warnings\n",
    "import glob\n",
    "import seaborn as sns\n",
    "import zipfile\n",
    "import shutil\n",
    "import scipy.stats as stats\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining directories\n",
    "current_dir = pathlib.Path().absolute()\n",
    "fa_dir = current_dir.parents[0].joinpath('src')\n",
    "# Importing fish_analyses module\n",
    "sys.path.append(str(fa_dir))\n",
    "import fish_analyses as fa\n",
    "# Local folder path\n",
    "local_folder_path = pathlib.Path().absolute().joinpath('temp_zip_analyses')\n",
    "local_folder_path\n",
    "# Path to credentials\n",
    "desktop_path = pathlib.Path.home()/'Desktop'\n",
    "# Connection to munsky-nas\n",
    "path_to_config_file = desktop_path.joinpath('config.yml')\n",
    "share_name = 'share'\n",
    "\n",
    "# creating a folder to store all plots\n",
    "destination_folder = pathlib.Path().absolute().joinpath('results', 'data_Huy')\n",
    "if not os.path.exists(destination_folder):\n",
    "    os.makedirs(destination_folder) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psf_z=350                # Theoretical size of the PSF emitted by a [rna] spot in the z plan, in nanometers\n",
    "psf_yx=160               # Theoretical size of the PSF emitted by a [rna] spot in the yx plan, in nanometers\n",
    "voxel_size_z=500         # Microscope conversion px to nanometers in the z axis.\n",
    "voxel_size_yx=160        # Microscope conversion px to nanometers in the xy axis.\n",
    "scale = np.array ([ voxel_size_z/psf_z, voxel_size_yx/psf_yx, voxel_size_yx/psf_yx ])\n",
    "\n",
    "list_timepoints = [0,18,300]\n",
    "list_thresholds_intensity =[400,450,500,550]\n",
    "list_thresholds_distance=[1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_spot_classification_from_df(df,show_plots = False,time_point=0,threshold_intensity=0,threshold_distance=0):\n",
    "    number_cells = df['cell_id'].nunique()\n",
    "    array_spot_type_per_cell = np.zeros((number_cells, 10)).astype(int) # this array will store the spots separated  as types: spot_0_only, spot_1_only, or spot_0_1\n",
    "    for cell_id in range(number_cells):\n",
    "        # retrieving the coordinates for spots type 0 and 1 for each cell \n",
    "        array_spots_0 = np.asarray( df[['z','y','x']][(df[\"cell_id\"] == cell_id) & (df[\"spot_type\"] == 0)] ) # coordinates for spot_type_0 with shape [num_spots_type_0, 3]\n",
    "        array_spots_1 = np.asarray( df[['z','y','x']][(df[\"cell_id\"] == cell_id) & (df[\"spot_type\"] == 1)] ) # coordinates for spot_type_1 with shape [num_spots_type_1, 3]\n",
    "        total_spots0 = array_spots_0.shape[0]\n",
    "        total_spots1 = array_spots_1.shape[0]\n",
    "        # Concatenating arrays from spots 0 and 1\n",
    "        array_all_spots = np.concatenate((array_spots_0,array_spots_1), axis=0) \n",
    "        # Calculating a distance matrix. \n",
    "        distance_matrix = np.zeros( (array_all_spots.shape[0], array_all_spots.shape[0])) #  the distance matrix is an square matrix resulting from the concatenation of both spot  types.\n",
    "        for i in range(len(array_all_spots)):\n",
    "            for j in range(len(array_all_spots)):\n",
    "                if j<i:\n",
    "                    distance_matrix[i,j] = np.linalg.norm( ( array_all_spots[i,:]-array_all_spots[j,:] ) * scale )\n",
    "        # masking the distance matrix. Ones indicate the distance is less or equal than threshold_distance\n",
    "        mask_distance_matrix = (distance_matrix <= threshold_distance) \n",
    "        # Selecting the right-lower quadrant as a subsection of the distance matrix that compares one spot type versus the other. \n",
    "        subsection_mask_distance_matrix = mask_distance_matrix[total_spots0:, 0:total_spots0].copy()\n",
    "        if show_plots == True:\n",
    "            plt.imshow(mask_distance_matrix, cmap='Greys_r')\n",
    "            plt.imshow(subsection_mask_distance_matrix,cmap='Greys_r')\n",
    "        \n",
    "        inv_subsection_mask_distance_matrix = ~subsection_mask_distance_matrix\n",
    "        # Calculating each type of spots in cell\n",
    "        is_spot_only_type_0 = np.all(inv_subsection_mask_distance_matrix, axis =0 ) # Testing if all the columns are ones of inv(subsection_mask_distance_matrix). Representing spot type 0. Notice that np.all(arr, axis=0) does the calculation along the columns.\n",
    "        is_spot_only_type_1 = np.all(inv_subsection_mask_distance_matrix, axis =1 ) #  Testing if all the rows are ones of inv(subsection_mask_distance_matrix). Representing spot type 1. Notice that np.all(arr, axis=1) does the calculation along the rows.    \n",
    "        \n",
    "        num_type_0_only = np.sum(is_spot_only_type_0) \n",
    "        num_type_1_only =np.sum(is_spot_only_type_1) \n",
    "        num_type_0_1 = (total_spots0 - num_type_0_only) + (total_spots1 - num_type_1_only) # Number of spots in both channels\n",
    "        array_spot_type_per_cell[cell_id,:] = np.array([time_point, threshold_intensity,threshold_distance, cell_id, num_type_0_only, num_type_1_only, num_type_0_1, num_type_0_only+num_type_0_1, \n",
    "                                                        num_type_1_only+num_type_0_1, num_type_0_only+num_type_1_only+num_type_0_1]).astype(int)\n",
    "        list_labels = ['time','ts_intensity','ts_distance','cell_id','num_0_only','num_1_only','num_0_1','num_0', 'num_1','total']\n",
    "        # creating a dataframe\n",
    "        df_spots_classification = pd.DataFrame(data=array_spot_type_per_cell, columns=list_labels)\n",
    "    return df_spots_classification  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of folders to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Huy_data(mandatory_substring):\n",
    "    list_dirs=(\n",
    "    'smFISH_images/Linda_smFISH_images/Confocal/20220714/MS2-CY5_Cyto543_560_woStim',\n",
    "    'smFISH_images/Linda_smFISH_images/Confocal/20220714/MS2-CY5_Cyto543_560_18minTPL_5uM' ,\n",
    "    'smFISH_images/Linda_smFISH_images/Confocal/20220714/MS2-CY5_Cyto543_560_5hTPL_5uM' )\n",
    "    list_labels = [ 'woSTM','18minTPL_5uM','5hTPL_5uM']\n",
    "    plot_title_suffix= \"MS2_CY5\"\n",
    "    mandatory_substring = mandatory_substring      #'nuc_70__cyto_0__psfz_350__psfyx_160__ts_400_400'\n",
    "    return list_dirs, list_labels, plot_title_suffix, mandatory_substring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "# Running the codes\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "substrings =[\n",
    "    'nuc_70__cyto_0__psfz_350__psfyx_160__ts_400_400',\n",
    "    'nuc_70__cyto_0__psfz_350__psfyx_160__ts_450_450',\n",
    "    'nuc_70__cyto_0__psfz_350__psfyx_160__ts_500_500',\n",
    "    'nuc_70__cyto_0__psfz_350__psfyx_160__ts_550_550' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to NAS and extracting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_df_paths=[]\n",
    "list_df_names=[]\n",
    "counter_dataframes =0\n",
    "\n",
    "for k, ts_distance in enumerate(list_thresholds_distance):\n",
    "    for j,mandatory_substring in enumerate(substrings):\n",
    "        list_dirs, list_labels, plot_title_suffix, mandatory_substring = Huy_data(mandatory_substring=mandatory_substring)\n",
    "        list_local_files = fa.Utilities.read_zipfiles_from_NAS(list_dirs,path_to_config_file,share_name, mandatory_substring, local_folder_path)\n",
    "        list_local_folders = fa.Utilities.unzip_local_folders(list_local_files,local_folder_path)\n",
    "        list_dataframes = fa.Utilities.extracting_data_for_each_df_in_directory(  list_local_folders=list_local_folders,current_dir=current_dir,minimal_TS_size=2)[6]\n",
    "        # Iterating for each time point (experimental condition)\n",
    "        for i,tp in enumerate (list_timepoints):\n",
    "            df_spots_classification = extract_spot_classification_from_df(df=list_dataframes[i],show_plots = False, time_point=tp, threshold_intensity = list_thresholds_intensity[j],threshold_distance=ts_distance )\n",
    "            df_name = plot_title_suffix+'_time_'+str(tp)+ '_int_'+str(list_thresholds_intensity[j])+ '_dist_'+str(ts_distance)\n",
    "            df_path=pathlib.Path().absolute().joinpath(destination_folder,df_name +'.csv')\n",
    "            df_spots_classification.to_csv(df_path, index = False)\n",
    "            df_spots_classification = \"\"\n",
    "            list_df_paths.append(df_path)\n",
    "            list_df_names.append(df_name)\n",
    "            counter_dataframes+=1\n",
    "        del list_dirs, list_labels, plot_title_suffix, mandatory_substring, list_local_files,list_local_folders,list_dataframes,df_path,df_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading all dataframes in a dictionary\n",
    "dic_dataframes = {}\n",
    "for df_index, df_name in enumerate (list_df_names):\n",
    "    dic_dataframes[df_name] = pd.read_csv(list_df_paths[df_index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_df_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate average number of both spots at time 0\n",
    "print(dic_dataframes['MS2_CY5_time_0_int_400_dist_1']['num_0_1'].values.mean())\n",
    "print(dic_dataframes['MS2_CY5_time_0_int_450_dist_1']['num_0_1'].values.mean())\n",
    "print(dic_dataframes['MS2_CY5_time_0_int_500_dist_1']['num_0_1'].values.mean())\n",
    "print(dic_dataframes['MS2_CY5_time_0_int_550_dist_1']['num_0_1'].values.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_df_paths=[]\n",
    "list_df_names=[]\n",
    "counter_dataframes =0\n",
    "plot_title_suffix= \"MS2_CY5\"\n",
    "for k, ts_distance in enumerate(list_thresholds_distance):\n",
    "    for j,mandatory_substring in enumerate(substrings):\n",
    "        # Iterating for each time point (experimental condition)\n",
    "        for i,tp in enumerate (list_timepoints):\n",
    "            df_name = plot_title_suffix+'_time_'+str(tp)+ '_int_'+str(list_thresholds_intensity[j])+ '_dist_'+str(ts_distance)\n",
    "            df_path=pathlib.Path().absolute().joinpath(destination_folder,df_name +'.csv')\n",
    "            list_df_paths.append(df_path)\n",
    "            list_df_names.append(df_name)\n",
    "            counter_dataframes+=1\n",
    "# Loading all dataframes in a dictionary\n",
    "dic_dataframes = {}\n",
    "for df_index, df_name in enumerate (list_df_names):\n",
    "    dic_dataframes[df_name] = pd.read_csv(list_df_paths[df_index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_number_spots_time_0 = np.zeros( (len(list_thresholds_intensity),len(list_thresholds_distance)) )\n",
    "for int, ts_intensity in enumerate(list_thresholds_intensity):\n",
    "    for d, ts_distance in enumerate(list_thresholds_distance):\n",
    "        df_name_loop = 'MS2_CY5_time_0_int_'+str(ts_intensity)+'_dist_'+str(ts_distance)\n",
    "        matrix_number_spots_time_0[int, d] = np.round( dic_dataframes[df_name_loop]['num_0_1'].values.mean(), 0)\n",
    "matrix_number_spots_time_0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "img = ax.imshow(matrix_number_spots_time_0,cmap='Blues')\n",
    "for (j,i),label in np.ndenumerate(matrix_number_spots_time_0):\n",
    "    ax.text(i,j,label,ha='center',va='center')\n",
    "ax.set_yticks([0,1,2,3])\n",
    "ax.set_xticks([0,1,2])\n",
    "ax.set_xticklabels(list_thresholds_distance)\n",
    "ax.set_yticklabels(list_thresholds_intensity)\n",
    "ax.set_xlabel('dist ts')\n",
    "ax.set_ylabel('int ts')\n",
    "ax.set_title('co-detected spots time 0')\n",
    "fig.colorbar(img)\n",
    "plt.grid(None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_number_spots_tme_18 = np.zeros( (len(list_thresholds_intensity),len(list_thresholds_distance)) )\n",
    "for int, ts_intensity in enumerate(list_thresholds_intensity):\n",
    "    for d, ts_distance in enumerate(list_thresholds_distance):\n",
    "        df_name_loop = 'MS2_CY5_time_18_int_'+str(ts_intensity)+'_dist_'+str(ts_distance)\n",
    "        matrix_number_spots_tme_18[int, d] = np.round( dic_dataframes[df_name_loop]['num_0_1'].values.mean(), 0)\n",
    "matrix_number_spots_tme_18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "img = ax.imshow(matrix_number_spots_tme_18,cmap='Blues')\n",
    "for (j,i),label in np.ndenumerate(matrix_number_spots_tme_18):\n",
    "    ax.text(i,j,label,ha='center',va='center')\n",
    "ax.set_yticks([0,1,2,3])\n",
    "ax.set_xticks([0,1,2])\n",
    "ax.set_xticklabels(list_thresholds_distance)\n",
    "ax.set_yticklabels(list_thresholds_intensity)\n",
    "ax.set_xlabel('dist ts')\n",
    "ax.set_ylabel('int ts')\n",
    "ax.set_title('co-detected spots time 18')\n",
    "fig.colorbar(img)\n",
    "plt.grid(None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_number_spots_tme_300 = np.zeros( (len(list_thresholds_intensity),len(list_thresholds_distance)) )\n",
    "for int, ts_intensity in enumerate(list_thresholds_intensity):\n",
    "    for d, ts_distance in enumerate(list_thresholds_distance):\n",
    "        df_name_loop = 'MS2_CY5_time_300_int_'+str(ts_intensity)+'_dist_'+str(ts_distance)\n",
    "        matrix_number_spots_tme_300[int, d] = np.round( dic_dataframes[df_name_loop]['num_0_1'].values.mean(), 0)\n",
    "matrix_number_spots_tme_300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "img = ax.imshow(matrix_number_spots_tme_300,cmap='Blues')\n",
    "for (j,i),label in np.ndenumerate(matrix_number_spots_tme_300):\n",
    "    ax.text(i,j,label,ha='center',va='center')\n",
    "ax.set_yticks([0,1,2,3])\n",
    "ax.set_xticks([0,1,2])\n",
    "ax.set_xticklabels(list_thresholds_distance)\n",
    "ax.set_yticklabels(list_thresholds_intensity)\n",
    "ax.set_xlabel('dist ts')\n",
    "ax.set_ylabel('int ts')\n",
    "ax.set_title('co-detected spots time 300')\n",
    "fig.colorbar(img)\n",
    "plt.grid(None)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f123aec772437107f61ad48bdc3e74202fc8f652e2fa44805dd8339e0a72f809"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('FISH_processing')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12 (default, Oct 12 2021, 13:49:34) \n[GCC 7.5.0]"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
