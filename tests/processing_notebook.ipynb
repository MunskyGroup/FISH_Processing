{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# FISH integrated analyses"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Importing libraries\n",
    "from sys import platform\n",
    "import sys\n",
    "# To import files from directories\n",
    "import os; from os import listdir; from os.path import isfile, join\n",
    "# Image reader\n",
    "from skimage import io ; from skimage.io import imread\n",
    "# Plotting\n",
    "import matplotlib as mpl ; import matplotlib.pyplot as plt \n",
    "import matplotlib.path as mpltPath\n",
    "# To manipulate arrays\n",
    "import numpy as np \n",
    "import random\n",
    "import re\n",
    "import math\n",
    "from tqdm.notebook import tqdm\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "# Figure style and size\n",
    "from matplotlib import gridspec\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import bigfish\n",
    "import bigfish.stack as stack\n",
    "import bigfish.segmentation as segmentation\n",
    "import bigfish.plot as plot\n",
    "import bigfish.detection as detection"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Deffining directories\n",
    "current_dir = pathlib.Path().absolute()\n",
    "fa_dir = current_dir.parents[0].joinpath('src')\n",
    "#data_dir = current_dir.parents[0].joinpath('dataBases').joinpath('MS2-Cy3')\n",
    "data_dir = current_dir.parents[0].joinpath('dataBases').joinpath('GAPDH_Exon_Cy5')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Importing fish_analyses module\n",
    "sys.path.append(str(fa_dir))\n",
    "import fish_analyses as fa"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (fish_analyses.py, line 908)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/home/luisub/Desktop/FISH_Processing/src/fish_analyses.py\"\u001b[0;36m, line \u001b[0;32m908\u001b[0m\n\u001b[0;31m    new_dataframe = pd.DataFrame( columns=['image_id', 'cell_id', 'spot_id','nucleus_y', 'nucleus_x','nuc_area_px','cyto_area_px', 'cell_area_px','z', 'y', 'x','is_nuc','is_cluster','cluster_size'])pd.DataFrame( columns=['image_id', 'cell_id', 'spot_id','nucleus_y', 'nucleus_x','nuc_area_px','cyto_area_px', 'cell_area_px','z', 'y', 'x','is_nuc','is_cluster','cluster_size'])\u001b[0m\n\u001b[0m                                                                                                                                                                                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "_, path_files, _, _ = fa.ReadImages(data_dir).read()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Reading data from local memory\n",
    "#list_file_names, list_merged_images, number_images, output_to_path = fa.MergeChannels(data_dir, substring_to_detect_in_file_name = '.*_C0.tif', save_figure =0).merge()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "list_images, path_files, list_files_names, number_images = fa.ReadImages(data_dir).read()\n",
    "#temp_img = stack.read_image(path_files[0])                                 # reading the image"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "remove_fragmented_cells = False\n",
    "for i in range(0,5):\n",
    "    masks_complete_cells, masks_nuclei, masks_cytosol_no_nuclei, index_paired_masks = fa.CellposeFISH(list_images[i],channel_with_cytosol=[1,2], channel_with_nucleus=0,diameter_cytosol =250, diamter_nucleus=200,remove_fragmented_cells= remove_fragmented_cells, show_plot=1).calculate_masks()  # Detect only nucleus"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mask_num = 3\n",
    "plt.imshow(masks_complete_cells[mask_num])\n",
    "plt.show()\n",
    "plt.imshow(masks_nuclei[mask_num])\n",
    "plt.show()\n",
    "plt.imshow(masks_cytosol_no_nuclei[mask_num])\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class DataProcessing():\n",
    "    '''\n",
    "    This class is intended to extract data from the class SpotDetection and return the data as a dataframe. \n",
    "    \n",
    "    Parameters\n",
    "    --  --  --  --  -- \n",
    "\n",
    "    spotDectionCSV: np.int64 Array with shape (nb_clusters, 5) or (nb_clusters, 4). \n",
    "            One coordinate per dimension for the clusters centroid (zyx or yx coordinates), the number of spots detected in the clusters and its index.\n",
    "    clusterDectionCSV : np.int64 with shape (nb_spots, 4) or (nb_spots, 3).\n",
    "            Coordinates of the detected spots . One coordinate per dimension (zyx or yx coordinates) plus the index of the cluster assigned to the spot. If no cluster was assigned, value is -1.\n",
    "    masks_complete_cells : List of NumPy arrays or a single NumPy array\n",
    "            Masks for every cell detected in the image. The list contains the mask arrays consisting of one or multiple Numpy arrays with format [Y, X].\n",
    "    masks_nuclei: List of NumPy arrays or a single NumPy array\n",
    "            Masks for every cell detected in the image. The list contains the mask arrays consisting of one or multiple Numpy arrays with format [Y, X].\n",
    "    masks_cytosol_no_nuclei : List of NumPy arrays or a single NumPy array\n",
    "            Masks for every cell detected in the image. The list contains the mask arrays consisting of one or multiple Numpy arrays with format [Y, X].\n",
    "    counter_total_cells : int, optional\n",
    "        index to indicate the number of cells on the dataframe. The default is 0.\n",
    "    dataframe : Pandas dataframe or None.\n",
    "        Pandas dataframe with the following columns. image_id, cell_id, spot_id, nucleus_y, nucleus_x, nuc_area_px, cyto_area_px, cell_area_px, z, y, x, is_nuc, is_cluster, cluster_size. The default is None.\n",
    "    '''\n",
    "    def __init__(self,spotDectionCSV, clusterDectionCSV,masks_complete_cells, masks_nuclei, masks_cytosol_no_nuclei, counter_total_cells=0,dataframe =None):\n",
    "        self.spotDectionCSV=spotDectionCSV \n",
    "        self.clusterDectionCSV=clusterDectionCSV\n",
    "        self.masks_complete_cells=masks_complete_cells\n",
    "        self.masks_nuclei=masks_nuclei\n",
    "        self.masks_cytosol_no_nuclei=masks_cytosol_no_nuclei\n",
    "        self.counter_total_cells=counter_total_cells\n",
    "        self.dataframe =dataframe\n",
    "\n",
    "\n",
    "    def get_dataframe(self):\n",
    "        '''\n",
    "        This method extracts data from the class SpotDetection and return the data as a dataframe.\n",
    "\n",
    "        Returns\n",
    "        --  --  -- -\n",
    "        dataframe,  : Pandas dataframe\n",
    "            Pandas dataframe with the following columns. image_id, cell_id, spot_id, nucleus_y, nucleus_x, nuc_area_px, cyto_area_px, cell_area_px, z, y, x, is_nuc, is_cluster, cluster_size.\n",
    "        counter_total_cells : int\n",
    "            Index indicating the number of cells in the current dataframe.\n",
    "        '''\n",
    "    \n",
    "        def mask_selector(masks, id,calculate_centroid= True):\n",
    "            temp_mask = np.zeros_like(masks) # making a copy of the image\n",
    "            selected_mask = temp_mask + (masks==id) # Selecting a single mask and making this mask equal to one and the background equal to zero.\n",
    "            mask_area = np.count_nonzero(selected_mask)\n",
    "            if calculate_centroid == True:\n",
    "                centroid_y,centroid_x = ndimage.measurements.center_of_mass(selected_mask)\n",
    "            else:\n",
    "                centroid_y,centroid_x = 0,0\n",
    "            return selected_mask , mask_area, centroid_y,centroid_x\n",
    "\n",
    "\n",
    "        def data_to_df( df, spotDectionCSV, clusterDectionCSV, mask_nuc = None, mask_cytosol_only=None, nuc_area = 0, cyto_area =0, cell_area=0, centroid_y=0, centroid_x=0, image_counter=0, cell_counter =0 ):\n",
    "            # spotDectionCSV      nrna x  [Z,Y,X,idx_foci]\n",
    "            # clusterDectionCSV   nc   x  [Z,Y,X,size,idx_foci]\n",
    "\n",
    "            # Removing TS from the image and calculating RNA in nucleus\n",
    "            spots_no_ts, _, ts = stack.remove_transcription_site(spotDectionCSV, clusterDectionCSV, mask_nuc, ndim=3)\n",
    "            #rna_out_ts      [Z,Y,X,idx_foci]         Coordinates of the detected RNAs with shape. One coordinate per dimension (zyx or yx coordinates) plus the index of the foci assigned to the RNA. If no foci was assigned, value is -1. RNAs from transcription sites are removed.\n",
    "            #foci            [Z,Y,X,size, idx_foci]   One coordinate per dimension for the foci centroid (zyx or yx coordinates), the number of RNAs detected in the foci and its index.\n",
    "            #ts              [Z,Y,X,size,idx_ts]      One coordinate per dimension for the transcription site centroid (zyx or yx coordinates), the number of RNAs detected in the transcription site and its index.\n",
    "            spots_nuc, _ = stack.identify_objects_in_region(mask_nuc, spots_no_ts, ndim=3)\n",
    "\n",
    "            # Detecting spots in the nucleus\n",
    "            spots_cytosol_only, _ = stack.identify_objects_in_region(mask_cytosol_only, spotDectionCSV[:,:3], ndim=3)\n",
    "            # coord_innp  Coordinates of the objects detected inside the region.\n",
    "            # coord_outnp Coordinates of the objects detected outside the region.\n",
    "\n",
    "            # ts                     n x [Z,Y,X,size,idx_ts]\n",
    "            # spots_nuc              n x [Z,Y,X]\n",
    "            # spots_cytosol_only     n x [Z,Y,X]\n",
    "\n",
    "            number_columns = len(df. columns)\n",
    "            num_ts = ts.shape[0]\n",
    "            num_nuc = spots_nuc.shape[0]\n",
    "            num_cyt = spots_cytosol_only.shape[0] \n",
    "\n",
    "            array_ts =                  np.zeros( ( num_ts,number_columns)  )\n",
    "            array_spots_nuc =           np.zeros( ( num_nuc,number_columns) )\n",
    "            array_spots_cytosol_only =  np.zeros( ( num_cyt  ,number_columns) )\n",
    "\n",
    "            # Spot index \n",
    "            spot_idx_ts =  np.arange(0,                  num_ts                                                 ,1 )\n",
    "            spot_idx_nuc = np.arange(num_ts,             num_ts + num_nuc                                       ,1 )\n",
    "            spot_idx_cyt = np.arange(num_ts + num_nuc,   num_ts + num_nuc + num_cyt  ,1 )\n",
    "            spot_idx = np.concatenate((spot_idx_ts,  spot_idx_nuc, spot_idx_cyt ))\n",
    "\n",
    "            # Populating arrays\n",
    "            array_ts[:,8:11] = ts[:,:3] # populating coord \n",
    "            array_ts[:,11] = 1          # is_nuc\n",
    "            array_ts[:,12] = 1          # is_cluster\n",
    "            array_ts[:,13] =  ts[:,3]   # cluster_size\n",
    "\n",
    "            array_spots_nuc[:,8:11] = spots_nuc[:,:3] # populating coord \n",
    "            array_spots_nuc[:,11] = 1                 # is_nuc\n",
    "            array_spots_nuc[:,12] = 0                 # is_cluster\n",
    "            array_spots_nuc[:,13] = 0                 # cluster_size\n",
    "\n",
    "            array_spots_cytosol_only[:,8:11] = spots_cytosol_only[:,:3] # populating coord \n",
    "            array_spots_cytosol_only[:,11] = 0                 # is_nuc\n",
    "            array_spots_cytosol_only[:,12] = 0                 # is_cluster\n",
    "            array_spots_cytosol_only[:,13] =  0                # cluster_size\n",
    "\n",
    "            # concatenate array\n",
    "            array_complete = np.vstack((array_ts, array_spots_nuc, array_spots_cytosol_only))\n",
    "            \n",
    "            # Saves a dataframe with zeros when no spots  are detected on the cell.\n",
    "            if array_complete.size ==0:\n",
    "                array_complete = np.zeros( ( 1,number_columns)  )\n",
    "                # if NO spots are detected populate  with -1\n",
    "                array_complete[:,2] = -1     # spot_id\n",
    "                array_complete[:,8:11] = -1\n",
    "            else:\n",
    "                # if spots are detected populate  the reported  array\n",
    "                array_complete[:,2] = spot_idx.T     # spot_id\n",
    "            # populating  array with cell  information\n",
    "            array_complete[:,0] = image_counter  # image_id\n",
    "            array_complete[:,1] = cell_counter   # cell_id\n",
    "            array_complete[:,3] = centroid_y     #'nuc_y_centoid'\n",
    "            array_complete[:,4] = centroid_x     #'nuc_x_centoid'\n",
    "            array_complete[:,5] = nuc_area       #'nuc_area_px'\n",
    "            array_complete[:,6] = cyto_area      # cyto_area_px\n",
    "            array_complete[:,7] = cell_area      #'cell_area_px'\n",
    "\n",
    "            # df = pd.DataFrame( columns=['image_id', 'cell_id', 'spot_id','nucleus_y', 'nucleus_x','nuc_area_px','cyto_area_px', 'cell_area_px','z', 'y', 'x','is_nuc','is_cluster','cluster_size'])\n",
    "            df = df.append(pd.DataFrame(array_complete, columns=df.columns), ignore_index=True)\n",
    "            return df\n",
    "\n",
    "\n",
    "        # Initializing Dataframe\n",
    "        if not ( dataframe is None):\n",
    "            dataframe = pd.DataFrame( columns=['image_id', 'cell_id', 'spot_id','nucleus_y', 'nucleus_x','nuc_area_px','cyto_area_px', 'cell_area_px','z', 'y', 'x','is_nuc','is_cluster','cluster_size'])\n",
    "        self.dataframe = dataframe \n",
    "\n",
    "        # loop for each cell in image\n",
    "        n_masks = np.amax(self.masks_nuclei)\n",
    "        for id_cell in range (1,n_masks+1): # iterating for each mask in a given cell. The mask has values from 0 for background, to int n, where n is the number of detected masks.\n",
    "            selected_nuc_mask , nuc_area, nuc_centroid_y, nuc_centroid_x      = mask_selector(self.masks_nuclei, id_cell)\n",
    "            selected_cyt_only_mask , cyto_area, _ ,_                          = mask_selector(self.masks_cytosol_no_nuclei, id_cell,calculate_centroid=False)\n",
    "            selected_cell_mask , cell_area, _, _                              = mask_selector(self.masks_complete_cells, id_cell,calculate_centroid=False)\n",
    "            # Data extraction\n",
    "            dataframe = data_to_df(self.dataframe, \n",
    "                                self.spotDectionCSV, \n",
    "                                self.clusterDectionCSV, \n",
    "                                mask_nuc = self.selected_nuc_mask, \n",
    "                                mask_cytosol_only=self.selected_cyt_only_mask, \n",
    "                                nuc_area=nuc_area,\n",
    "                                cyto_area=cyto_area, \n",
    "                                cell_area=cell_area, \n",
    "                                centroid_y = nuc_centroid_y, \n",
    "                                centroid_x = nuc_centroid_x,\n",
    "                                image_counter=i,\n",
    "                                cell_counter =counter_total_cells)\n",
    "            counter_total_cells +=1\n",
    "        return dataframe, counter_total_cells"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "raise"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def plot_original_images(image, figsize=(8.5, 5)):\n",
    "  '''\n",
    "  This function plots all the channels for the original image.\n",
    "  '''\n",
    "  #print(' \\n ####### ---ORIGINAL IMAGE--- ####### \\n')\n",
    "  number_channels = image.shape[3]\n",
    "  fig, axes = plt.subplots(nrows=1, ncols=number_channels, figsize=figsize)\n",
    "  for i in range (0,number_channels ):\n",
    "    img_2D = stack.focus_projection(image[:,:,:,i], proportion=0.7, neighborhood_size=7, method='max') # maximum projection \n",
    "    img_2D = stack.gaussian_filter(img_2D,sigma=5)\n",
    "    axes[i].imshow( img_2D ,cmap='viridis') \n",
    "    axes[i].set_title('Channel_'+str(i))\n",
    "  plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def image_extraction(image_or_path, nucleus_channel= None, cell_channel=None, FISH_channel_experiment_0=None, FISH_channel_experiment_1=None,show_plot=False):\n",
    "  '''\n",
    "  This function is inteded to extract all information from the file path and return 2D, maximum projections, and 3D images for the nucleus, cell, and RNA channels.\n",
    "  '''\n",
    "  if type(image_or_path) ==np.ndarray:\n",
    "    image = image_or_path                                              # loading the image\n",
    "  else:\n",
    "    image = stack.read_image(image_or_path)                            # reading the image\n",
    "    print('not reading')\n",
    "  sliceNum = image.shape[0]//2                                         # selecting the slice in the medium of the stack\n",
    "  def image_extraction_function(img,sliceNum,selected_channel=None):\n",
    "    if not ( selected_channel is None):\n",
    "      img_3D = img[:,:,:,selected_channel]                               # 3D image \n",
    "      img_2D = stack.focus_projection(img[:,:,:,selected_channel], proportion=0.7, neighborhood_size=7, method='max') # maximum projection \n",
    "      img_2D = stack.gaussian_filter(img_2D,sigma=5)\n",
    "    else:\n",
    "      img_3D,img_2D = None, None\n",
    "    return img_3D,img_2D\n",
    "  nuc_3D,nuc_2D = image_extraction_function(image,sliceNum,selected_channel=nucleus_channel)\n",
    "  cell_3D,cell_2D = image_extraction_function(image,sliceNum,selected_channel=cell_channel)\n",
    "  fish_0_3D, fish_0_2D = image_extraction_function(image,sliceNum,selected_channel=FISH_channel_experiment_0)\n",
    "  fish_1_3D, fish_1_2D = image_extraction_function(image,sliceNum,selected_channel=FISH_channel_experiment_1)\n",
    "  ## Plotting\n",
    "  if show_plot == True:\n",
    "    plot_original_images(image, figsize=(8.5, 5))\n",
    "  return nuc_3D, nuc_2D, cell_3D, cell_2D, fish_0_3D, fish_0_2D, fish_1_3D, fish_1_2D"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "nucleus_channel = 0 \n",
    "cell_channel = 1\n",
    "FISH_channel_experiment_0 = 2 \n",
    "FISH_channel_experiment_1 = None\n",
    "nuc_3D, nuc_2D, cell_3D, cell_2D, fish_0_3D, fish_0_2D, fish_1_3D, fish_1_2D = image_extraction(list_images[0], nucleus_channel, cell_channel, FISH_channel_experiment_0, FISH_channel_experiment_1,show_plot=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def remove_fragmented(img_masks):\n",
    "    img_masks_copy = np.copy(img_masks)\n",
    "    for nm in range(1,np.amax(img_masks)+1):\n",
    "        tested = np.where(img_masks_copy == nm, 1, 0)   # making zeros all elements outside each mask, and once all elements inside of each mask.\n",
    "        # testing if tested is touching the border of the image\n",
    "        is_border = np.any( np.concatenate( ( tested[:,0],tested[:,-1],tested[0,:],tested[-1,:] ) ) )\n",
    "        if is_border == True:\n",
    "            img_masks = np.where(img_masks == nm, 0, img_masks)\n",
    "    return img_masks"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def nucleus_segmentation(nuc_img_2D,use_unet_nuc=True, thresholdLabel_nuc=None,small_object_size_nuc=5000,remove_fragmented_masks=True):\n",
    "    is_border = lambda img: np.any( np.concatenate( ( img[:,0],img[:,-1],img[0,:],img[-1,:] ) ) )\n",
    "    if use_unet_nuc == True: # segmentation using U-net\n",
    "        model_nuc = segmentation.unet_3_classes_nuc() # load pretrained model\n",
    "        nuc_label = segmentation.apply_unet_3_classes(model_nuc, nuc_img_2D, target_size=256, test_time_augmentation=True) # instance segmentation\n",
    "    else: # Cell segmentation using watershed\n",
    "        nuc_label = segmentation.thresholding(nuc_img_2D, threshold=thresholdLabel_nuc)\n",
    "    #Cleaning results\n",
    "    if remove_fragmented_masks==True:\n",
    "        nuc_label = remove_fragmented(nuc_label)\n",
    "    nuc_label = segmentation.clean_segmentation(nuc_label,  smoothness=10, small_object_size=small_object_size_nuc, delimit_instance=True,fill_holes=True)\n",
    "    nuc_label= segmentation.remove_disjoint(nuc_label)\n",
    "    return nuc_label"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def cytosol_segmentation(cell_img_2D,nuc_label,nuc_img_2D=None,use_unet_cell=False, thresholdLabel_cell=None,small_object_size_cell=10000,remove_fragmented_masks=True):\n",
    "    if use_unet_cell == True: # segmentation using U-net \n",
    "        model_cell = segmentation.unet_distance_edge_double() \n",
    "        cell_label = segmentation.apply_unet_distance_double(model_cell, nuc=nuc_img_2D, cell=cell_img_2D, nuc_label=nuc_label, target_size=256, test_time_augmentation=True) # instance segmentation\n",
    "    else: # Cell segmentation using watershed\n",
    "        cell_label = segmentation.cell_watershed(cell_img_2D, nuc_label, threshold=thresholdLabel_cell, alpha=0.8)\n",
    "        \n",
    "    if remove_fragmented_masks==True:\n",
    "        cell_label = remove_fragmented(cell_label)\n",
    "    cell_label = segmentation.clean_segmentation(cell_label, smoothness=10, small_object_size=small_object_size_cell, delimit_instance=True,fill_holes=True)\n",
    "    cell_label= segmentation.remove_disjoint(cell_label)\n",
    "    return cell_label"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def match_nuc_and_cell(nuc_label, cell_label):\n",
    "    # mathcing nuc and cell labels\n",
    "    segmentationNucLabel, segmentationCellLabel = segmentation.match_nuc_cell(nuc_label, cell_label, single_nuc=False, cell_alone=False)\n",
    "    # Creating cytosol_only_mask\n",
    "    if np.amax(segmentationNucLabel) ==0:\n",
    "        #print('No marches between nucleus and cytosol masks')\n",
    "        segmentationNucLabel, segmentationCellLabel,segmentation_cytosol_only = nuc_label, cell_label, np.zeros_like(segmentationNucLabel)\n",
    "    else:\n",
    "        segmentation_cytosol_only = np.zeros_like(segmentationNucLabel)\n",
    "        for nm in range(1,np.amax(segmentationNucLabel)+1):\n",
    "            nuc_copy = segmentationNucLabel.copy()\n",
    "            cell_copy = segmentationCellLabel.copy()\n",
    "            tested_nuc_mask = np.where(nuc_copy == nm, -1, 0)    # making zeros all elements outside each mask, and -1 all elements inside of each mask.\n",
    "            tested_cell_mask = np.where(cell_copy == nm, 1, 0)   # making zeros all elements outside each mask, and once all elements inside of each mask.\n",
    "            merged = tested_nuc_mask + tested_cell_mask          # substracting nuc from cytosol\n",
    "            merged = np.where(merged == 1, nm, 0)\n",
    "            segmentation_cytosol_only = segmentation_cytosol_only + merged             # populating cytosol_only_mask with int that match the order in segmentationNucLabel and segmentationCellLabel\n",
    "    return segmentationNucLabel, segmentationCellLabel, segmentation_cytosol_only"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def cytosol_objective_function(cell_img_2D,nuc_label,nuc_img_2D=None, thresholdLabel_cell =495,remove_fragmented_cells=True ,small_object_size_cell=10000):\n",
    "    # segments images, only one image at a time is passed through function \n",
    "    counter_total_cells = 0\n",
    "    number_detected_cells = []\n",
    "    # Cell segmentation\n",
    "    cell_label = cytosol_segmentation(cell_img_2D,nuc_label,nuc_img_2D=nuc_img_2D,use_unet_cell=False, thresholdLabel_cell=thresholdLabel_cell,small_object_size_cell=small_object_size_cell,remove_fragmented_masks=remove_fragmented_cells)\n",
    "    # Matching nucleus and cell\n",
    "    segmentationNucLabel, segmentationCellLabel,segmentation_cytosol_only= match_nuc_and_cell(nuc_label, cell_label)\n",
    "    masks_cytosol = segmentation_cytosol_only\n",
    "    number_detected_cells = np.amax(segmentation_cytosol_only)\n",
    "    if number_detected_cells ==0:\n",
    "        masks_cytosol = np.zeros_like(segmentation_cytosol_only)\n",
    "    # Objective Function calculation\n",
    "    area_in_all_cells = np.count_nonzero(segmentationCellLabel)  # total cells area\n",
    "    obj_return_vector = number_detected_cells * area_in_all_cells # objective function output = [Total area * number of cells]\n",
    "    return obj_return_vector"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def mask_optimization_function(nuc_2D, cell_2D,thres_begin =400, thres_end = 600,num_ts=30,remove_fragmented_cells=True,show_plot=False):\n",
    "  vector_thresholds = np.linspace(thres_begin,thres_end,num_ts) # Range of thresholds tested Spaces threshold values by 1\n",
    "  obj_return_vector = np.zeros((len(vector_thresholds)))  # Preallocation for objective function output [Total area * number of cells]\n",
    "  # Nucleus segmentation\n",
    "  nuc_label = nucleus_segmentation(nuc_2D,use_unet_nuc=True, thresholdLabel_nuc=None,small_object_size_nuc=5000,remove_fragmented_masks=True)\n",
    "  # code for cytosol optimization\n",
    "  for i in range(len(vector_thresholds)):\n",
    "    obj_return_vector[i]  = cytosol_objective_function(cell_2D,nuc_label,nuc_img_2D=nuc_2D, thresholdLabel_cell =vector_thresholds[i],remove_fragmented_cells=True ,small_object_size_cell=10000)\n",
    "  obj_return_vector[obj_return_vector==0]=1\n",
    "  obj_max_position = np.argmax(obj_return_vector) # Location of maximum value\n",
    "  selected_threshold = vector_thresholds[obj_max_position] # threshold at max\n",
    "  # Plotting\n",
    "  if show_plot== True:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(vector_thresholds, obj_return_vector,linewidth=3,color='b')# Plots Objective Function\n",
    "    plt.plot([selected_threshold,selected_threshold],[np.amin(obj_return_vector), np.amax(obj_return_vector)  ],linewidth=3,color='r')# Plots Objective Function\n",
    "    plt.ylabel(\"Number of cells * area\")\n",
    "    plt.xlabel(\"Thresholds\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.show()\n",
    "  # Returns the threshold that give the max and the max value\n",
    "  return selected_threshold"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def segmentation_complete(nuc_2D, cell_2D,use_unet_nuc=True, use_unet_cell=False ,thresholdLabel_cell=500,small_object_size_nuc=5000,small_object_size_cell=10000,remove_fragmented_masks=True,show_plot=False):\n",
    "    # Nucleus segmentation\n",
    "    nuc_label = nucleus_segmentation(nuc_2D,use_unet_nuc=use_unet_nuc, thresholdLabel_nuc=None,small_object_size_nuc=small_object_size_nuc,remove_fragmented_masks=remove_fragmented_masks)\n",
    "    # Cell segmentation\n",
    "    cell_label = cytosol_segmentation(cell_2D,nuc_label,nuc_img_2D=nuc_2D,use_unet_cell=use_unet_cell, thresholdLabel_cell=thresholdLabel_cell,small_object_size_cell=small_object_size_cell,remove_fragmented_masks=remove_fragmented_masks)\n",
    "    # Matching nucleus and cell\n",
    "    segmentationNucLabel, segmentationCellLabel,segmentation_cytosol_only= match_nuc_and_cell(nuc_label, cell_label)\n",
    "    # Plotting\n",
    "    if show_plot== True:\n",
    "        plot.plot_images([ segmentationNucLabel, segmentationCellLabel ,  segmentation_cytosol_only], titles=[\"Nucleus\", \"Cytosol\",\"Cytosol_only\" ], framesize=(8.5, 5))\n",
    "        plt.show() \n",
    "    return segmentationNucLabel, segmentationCellLabel,segmentation_cytosol_only"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "nucleus_channel = 0\n",
    "cell_channel = 2\n",
    "FISH_channel_experiment_0 = 2\n",
    "num_tested_thresholds = 30         \n",
    "remove_fragmented_cells = True \n",
    "show_plot = True\n",
    "thres_begin = 400\n",
    "thres_end = 1000\n",
    "# Auto threshold selection\n",
    "nuc_3D, nuc_2D, cell_3D, cell_2D, fish_0_3D, fish_0_2D, fish_1_3D, fish_1_2D = image_extraction(list_images[2], nucleus_channel, cell_channel, FISH_channel_experiment_0, FISH_channel_experiment_1,show_plot=show_plot)\n",
    "selected_threshold = mask_optimization_function( nuc_2D, cell_2D,thres_begin =thres_begin, thres_end = thres_end,num_ts=num_tested_thresholds,remove_fragmented_cells=remove_fragmented_cells,show_plot=show_plot) \n",
    "segmentationNucLabel, segmentationCellLabel,segmentation_cytosol_only = segmentation_complete(nuc_2D, cell_2D, thresholdLabel_cell=selected_threshold,small_object_size_nuc=5000,small_object_size_cell=10000,remove_fragmented_masks=False,show_plot=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "raise"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os; from os import listdir; from os.path import isfile, join\n",
    "import re  \n",
    "#from skimage import io \n",
    "from skimage.io import imread\n",
    "# To manipulate arrays\n",
    "import numpy as np \n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "from timeit import default_timer as timer\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import pathlib\n",
    "import sys\n",
    "from skimage.exposure import rescale_intensity\n",
    "import rsnapsim as rss\n",
    "from skimage.measure import find_contours\n",
    "# Plotting\n",
    "import matplotlib as mpl ; import matplotlib.pyplot as plt \n",
    "# To create interactive elements\n",
    "import ipywidgets as widgets ; from ipywidgets import interact, interactive, fixed, interact_manual, Button, HBox, VBox, Layout, GridspecLayout ; from IPython.display import Image\n",
    "\n",
    "import dna_features_viewer\n",
    "from dna_features_viewer import BiopythonTranslator, GraphicFeature, GraphicRecord, CircularGraphicRecord\n",
    "\n",
    "# Parallel computing\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "num_cores = multiprocessing.cpu_count()"
   ],
   "outputs": [],
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Deffining directories\n",
    "current_dir = pathlib.Path().absolute()\n",
    "sequences_dir = current_dir.parents[1].joinpath('DataBases','gene_files')\n",
    "video_dir = current_dir.parents[1].joinpath('DataBases','videos_for_sim_cell')\n",
    "#trajectories_dir = current_dir.parents[1].joinpath('DataBases','rsnapsim_simulations','bactin_ssa.npy')\n",
    "trajectories_dir = current_dir.parents[1].joinpath('DataBases','rsnapsim_simulations','kdm5b_ssa.npy')\n",
    "rsnaped_dir = current_dir.parents[1].joinpath('rsnaped')\n",
    "gene_file = current_dir.parents[1].joinpath('DataBases','gene_files','KDM5B_withTags.txt')"
   ],
   "outputs": [],
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Paths to dropbox\n",
    "from sys import platform as _platform\n",
    "if _platform == \"linux\" or _platform == \"linux2\":\n",
    "    dropbox_address = pathlib.Path('/','home','luisub','Dropbox', 'Project_rSNAPed','manuscript','Figures')\n",
    "elif _platform == \"darwin\":\n",
    "    dropbox_address = pathlib.Path('/','Users','luisaguilera','Dropbox', 'Project_rSNAPed','manuscript','Figures')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Importing rSNAPed\n",
    "sys.path.append(str(rsnaped_dir))\n",
    "import rsnaped as rsp"
   ],
   "outputs": [],
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['lines.linewidth'] = 1\n",
    "plt.rcParams['axes.linewidth'] = 1.5\n",
    "plt.rcParams['axes.grid'] = False"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from dna_features_viewer import BiopythonTranslator\n",
    "class MyCustomTranslator(BiopythonTranslator):\n",
    "    \"\"\"Custom translator\n",
    "    \"\"\"\n",
    "    def compute_feature_color(self, feature):\n",
    "        if feature.type == \"CDS\":\n",
    "            return \"#57B956\"\n",
    "        elif feature.type == \"FLAG\":\n",
    "            return \"#ff0000\"\n",
    "        elif feature.type == \"MS2\":\n",
    "            return \"#098BF5\"\n",
    "        elif feature.type == \"PP7\": \n",
    "            return \"#EB5559\"\n",
    "        else:\n",
    "            return \"#C4B07B\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plasmid sequences\n",
    "gene_file_pUB_SM_KDM5B_PP7 = str(sequences_dir.joinpath('kdm5b.gb')) # plasmid pUB_SM_KDM5B_PP7 \n",
    "graphic_record = MyCustomTranslator().translate_record(gene_file_pUB_SM_KDM5B_PP7) \n",
    "ax, _ = graphic_record.plot(figure_width=20, strand_in_label_threshold=7)\n",
    "#ax.set_title('pUB_SM_KDM5B_PP7 (1895 codons)')\n",
    "graphic_record.plot_legend(ax=ax, loc=1, ncol=3, frameon=False)\n",
    "name_figure = 'sequence.png'\n",
    "figure_directory = str(dropbox_address.joinpath(name_figure ) )\n",
    "ax.figure.savefig(figure_directory)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.style.use('ggplot')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# These are the parameters that need to be tested. \n",
    "number_of_simulated_cells = 1 # PLEASE TEST MIN 1 MAX 10\n",
    "number_spots_per_cell = 100     # PLEASE TEST MIN 5 MAX 200\n",
    "diffusion_coefficient = 0.7    # PLEASE TEST MIN 0.1 MAX 2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "intensity_calculation_method = 'disk_donut'  # options are : 'total_intensity' and 'disk_donut' 'gaussian_fit'\n",
    "mask_selection_method = 'max_area' # options are : 'max_spots' and 'max_area' \n",
    "use_optimization_for_tracking = 1 # 0 not using, 1 is using optimization\n",
    "frame_selection_empty_video = 'shuffle' # Options are: 'constant' , 'shuffle' and 'loop'"
   ],
   "outputs": [],
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "particle_size = 7 # spot size for the simulation and tracking.\n",
    "elongation_rate = 10\n",
    "initiation_rate = 0.03"
   ],
   "outputs": [],
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Perturbations\n",
    "use_Harringtonin = 0\n",
    "use_FRAP =0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "if use_FRAP == 1:\n",
    "    name_files = 'FRAP'\n",
    "    simulation_time_in_sec = 301    \n",
    "    perturbation_time_start = 100\n",
    "    perturbation_time_stop = 105\n",
    "    \n",
    "if use_Harringtonin ==1:\n",
    "    name_files = 'HT'\n",
    "    simulation_time_in_sec = 801    \n",
    "    perturbation_time_start = 400\n",
    "    perturbation_time_stop = 0\n",
    "\n",
    "if (use_FRAP ==0 ) and (use_Harringtonin==0):\n",
    "    name_files = 'SIM_'\n",
    "    simulation_time_in_sec = 801    \n",
    "    perturbation_time_start = 0\n",
    "    perturbation_time_stop = 0\n",
    "    \n",
    "if (use_FRAP ==1 ) and (use_Harringtonin==1):\n",
    "    raise ValueError ('FRAP and HT can not be deffined at the same time')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "intensity_scale_ch0 = 100\n",
    "intensity_scale_ch1 = 200\n",
    "intensity_scale_ch2 = 200"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "particle_detection_size = particle_size"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Running the simulations"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def fun_simulated_cells(current_dir, video_dir,ke=3,ki=0.03,gene_file =None, trajectories_dir=None, number_of_simulated_cells=3,number_spots_per_cell=80,\n",
    "    simulation_time_in_sec =100,step_size_in_sec=1,particle_size=5, diffusion_coefficient =1,path_to_rSNAPsim= None, path_to_save_output='temp',\n",
    "    intensity_calculation_method='gaussian_fit',frame_selection_empty_video=frame_selection_empty_video,\n",
    "    perturbation_time_start=perturbation_time_start,perturbation_time_stop=perturbation_time_stop,use_Harringtonin=use_Harringtonin,use_FRAP=use_FRAP ):\n",
    "    spot_size = particle_size\n",
    "    spot_sigma = 1\n",
    "    # Code that creates the folder to store results.\n",
    "    diffusion_coefficient_string = str(diffusion_coefficient).replace('.','_')\n",
    "    directory_name = 'Simulation_V2__'+'ns_'+str(number_spots_per_cell) +'_diff_'+ diffusion_coefficient_string \n",
    "    path_to_save_output = 'temp'\n",
    "    save_to_path =  current_dir.joinpath(path_to_save_output , directory_name )\n",
    "    if not os.path.exists(str(save_to_path)):\n",
    "        os.makedirs(str(save_to_path))\n",
    "    else:\n",
    "        shutil.rmtree(str(save_to_path))\n",
    "        os.makedirs(str(save_to_path))\n",
    "    counter = 0\n",
    "    ## Main loop that creates each cell and dataframe\n",
    "    for cell_number in range (0, number_of_simulated_cells):\n",
    "        output_directory_name = str(video_dir)\n",
    "        list_files_names = sorted([f for f in listdir(output_directory_name) if isfile(join(output_directory_name, f)) and ('.tif') in f], key=str.lower)  # reading all tif files in the folder\n",
    "        list_files_names.sort(key=lambda f: int(re.sub('\\D', '', f)))  # sorting the index in numerical order\n",
    "        path_files = [ str(video_dir.joinpath(f).resolve()) for f in list_files_names ] # creating the complete path for each file\n",
    "        selected_video = 7\n",
    "        video_path = path_files[selected_video]        \n",
    "        video = imread(video_path) \n",
    "        # Reducing in a half the intensity in the original video\n",
    "        video = video//2\n",
    "        empty_videos = video\n",
    "        counter +=1\n",
    "        if counter>=len(path_files):\n",
    "            counter =0\n",
    "        if not (trajectories_dir is None ):\n",
    "            # Loading trajectories from file\n",
    "            ssa_trajectories = np.load(str(trajectories_dir))\n",
    "            random_index_ch0 = np.random.randint(low=0, high=ssa_trajectories.shape[0]-1, size=(number_spots_per_cell,))\n",
    "            random_index_ch1 = np.random.randint(low=0, high=ssa_trajectories.shape[0]-1, size=(number_spots_per_cell,))\n",
    "            random_index_ch2 = np.random.randint(low=0, high=ssa_trajectories.shape[0]-1, size=(number_spots_per_cell,))\n",
    "            \n",
    "            simulated_trajectories_ch0 = ssa_trajectories[random_index_ch0,0:simulation_time_in_sec:step_size_in_sec] / 10 # converting to ump\n",
    "            simulated_trajectories_ch1 = ssa_trajectories[random_index_ch1,0:simulation_time_in_sec:step_size_in_sec] / 10 # converting to ump\n",
    "            simulated_trajectories_ch2 =  ssa_trajectories[random_index_ch2,0:simulation_time_in_sec:step_size_in_sec] / 10 # converting to ump\n",
    "        else:\n",
    "            # Simulations for intensity\n",
    "            ssa1,ssa1_ump,_ = rsp.SSA_rsnapsim(gene_file,ke,ki,frames=simulation_time_in_sec,frame_rate=1,n_traj=number_spots_per_cell,use_Harringtonin=use_Harringtonin,use_FRAP=use_FRAP, perturbation_time_start=perturbation_time_start,perturbation_time_stop=perturbation_time_stop).simulate() # rss.ssa_solver(n_traj = number_spots_per_cell, start_time=starting_time,tf=starting_time+n_frames, tstep=starting_time+n_frames,k_elong_mean=3, k_initiation=.03)  # tstep = total number of steps including the burnin time \n",
    "            simulated_trajectories_ch1 = ssa1_ump\n",
    "            ssa2,ssa2_ump,_ =  rsp.SSA_rsnapsim(gene_file,ke,ki,frames=simulation_time_in_sec,frame_rate=1,n_traj=number_spots_per_cell,use_Harringtonin=use_Harringtonin,use_FRAP=use_FRAP, perturbation_time_start=perturbation_time_start,perturbation_time_stop=perturbation_time_stop).simulate() # rss.ssa_solver(n_traj = number_spots_per_cell, start_time=starting_time,tf=starting_time+n_frames, tstep=starting_time+n_frames,k_elong_mean=3, k_initiation=.03)  # tstep = total number of steps including the burnin time \n",
    "            simulated_trajectories_ch2 = ssa2_ump\n",
    "            simulated_trajectories_ch0 = simulated_trajectories_ch1\n",
    "        #simulated_trajectories_ch0 = None\n",
    "        # Running the cell simulation\n",
    "        saved_file_name = str(save_to_path.joinpath('sim_cell_'+str(cell_number)))\n",
    "        tensor_video , spot_positions_movement, DataFrame_particles_intensities = rsp.SimulatedCell( base_video=video, number_spots = number_spots_per_cell, number_frames=simulation_time_in_sec, step_size=step_size_in_sec, diffusion_coefficient =diffusion_coefficient, simulated_trajectories_ch0=simulated_trajectories_ch0, size_spot_ch0=spot_size, spot_sigma_ch0=spot_sigma, simulated_trajectories_ch1=simulated_trajectories_ch1, size_spot_ch1=spot_size, spot_sigma_ch1=spot_sigma, simulated_trajectories_ch2=simulated_trajectories_ch2, size_spot_ch2=spot_size, spot_sigma_ch2=spot_sigma, ignore_ch0=0,ignore_ch1=0, ignore_ch2=1,save_as_tif_uint8=0,save_as_tif =1,save_as_gif=0, save_dataframe=1, saved_file_name=saved_file_name,create_temp_folder = False, intensity_calculation_method=intensity_calculation_method,perform_video_augmentation=0,frame_selection_empty_video=frame_selection_empty_video ,intensity_scale_ch0 = intensity_scale_ch0,intensity_scale_ch1 = intensity_scale_ch1,intensity_scale_ch2 = intensity_scale_ch2).make_simulation()      \n",
    "        #print ('The results are saved in folder: ', saved_file_name)\n",
    "    return save_to_path, simulated_trajectories_ch0, simulated_trajectories_ch1, simulated_trajectories_ch2, empty_videos"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# running the simulation\n",
    "start = timer()\n",
    "output_directory_name, simulated_trajectories_ch0, simulated_trajectories_ch1, simulated_trajectories_ch2, empty_videos = fun_simulated_cells(current_dir,video_dir,ke=elongation_rate, ki=initiation_rate,trajectories_dir=None,gene_file= gene_file, number_of_simulated_cells=number_of_simulated_cells,number_spots_per_cell=number_spots_per_cell,simulation_time_in_sec =simulation_time_in_sec,step_size_in_sec=1,particle_size=particle_size, diffusion_coefficient=diffusion_coefficient,path_to_rSNAPsim= None,intensity_calculation_method=intensity_calculation_method,frame_selection_empty_video=frame_selection_empty_video,perturbation_time_start=perturbation_time_start,perturbation_time_stop=perturbation_time_stop,use_Harringtonin=use_Harringtonin,use_FRAP=use_FRAP)\n",
    "end = timer()\n",
    "print('Time to generate simulated data:',round(end - start), ' sec')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "output_directory_name"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Reads the folder with the results and import the simulations as lists\n",
    "list_files_names = sorted([f for f in listdir(output_directory_name) if isfile(join(output_directory_name, f)) and ('.tif') in f], key=str.lower)  # reading all tif files in the folder\n",
    "list_files_names.sort(key=lambda f: int(re.sub('\\D', '', f)))  # sorting the index in numerical order\n",
    "path_files = [ str(output_directory_name.joinpath(f).resolve()) for f in list_files_names ] # creating the complete path for each file\n",
    "\n",
    "# Reading the microscopy data\n",
    "list_videos_original = [imread(f)[:,:,:,:] for f in  path_files] # List with all the videos\n",
    "nimg = number_of_simulated_cells"
   ],
   "outputs": [],
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Rescaling images\n",
    "rescale_video = False\n",
    "if rescale_video == True:\n",
    "    list_videos = []\n",
    "    number_channels = list_videos_original[0].shape[-1]\n",
    "    number_z_slices = list_videos_original[0].shape[0]\n",
    "    for i in range (0,nimg ):\n",
    "        temp_img = np.zeros_like(list_videos_original[0])\n",
    "        for j in range(0,number_channels):\n",
    "            temp_img[:,:,:,j] =  np.asarray( [ rescale_intensity(list_videos_original[i][z,:,:,j], in_range='image', out_range='dtype')  for z in range (0, number_z_slices)]  )\n",
    "        list_videos.append(temp_img)\n",
    "else:\n",
    "    list_videos = list_videos_original"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Display results as images"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def df_to_array(dataframe_simulated_cell):\n",
    "    '''\n",
    "    This function takes the dataframe and extracts the information from it. \n",
    "    Information is separated by particles. Notice that dataframe contains information about 600 particles.\n",
    "\n",
    "    Input\n",
    "        dataframe_simulated_cell : pandas dataframe\n",
    "\n",
    "    Returns\n",
    "        I_g : Intensities for each particle in the green channel. NumPy array with dimensions [number_particles, time_points]\n",
    "        I_g_std : Std for the intensities for each particle in the green channel.  NumPy array with dimensions [number_particles, time_points]\n",
    "        I_r : Intensities for each particle in the red channel. NumPy array with dimensions [number_particles, time_points]\n",
    "        I_r_std : Std for the intensities for each particle in the red channel. NumPy array with dimensions [number_particles, time_points]\n",
    "        x_loc : x position for each particle in the dataframe. NumPy array with dimensions [number_particles, time_points]\n",
    "        y_loc : y position for each particle in the dataframe. NumPy array with dimensions [number_particles, time_points]\n",
    "  \n",
    "    '''\n",
    "    # get the total number of particles in all cells\n",
    "    total_particles = 0\n",
    "    for cell in set(dataframe_simulated_cell['cell_number']):\n",
    "        total_particles += len(set(dataframe_simulated_cell[dataframe_simulated_cell['cell_number'] == 0]['particle'] ))\n",
    "\n",
    "    #preallocate numpy array sof n_particles by nframes\n",
    "    I_g = np.zeros([total_particles, np.max(dataframe_simulated_cell['frame'])+1] )  #intensity green\n",
    "    I_g_std = np.zeros([total_particles, np.max(dataframe_simulated_cell['frame'])+1] ) #intensity green std\n",
    "    x_loc = np.zeros([total_particles, np.max(dataframe_simulated_cell['frame'])+1] ) #x loc\n",
    "    y_loc = np.zeros([total_particles, np.max(dataframe_simulated_cell['frame'])+1] ) #y_loc\n",
    "    I_r_std   = np.zeros([total_particles, (np.max(dataframe_simulated_cell['frame'])+1)] ) #intensity red\n",
    "    I_r = np.zeros([total_particles, (np.max(dataframe_simulated_cell['frame'])+1) ] ) #intensity red std\n",
    "    k = 0\n",
    "\n",
    "    # For loops that iterate for each particle and stores the data in the previously pre-alocated arrays.\n",
    "    for cell in set(dataframe_simulated_cell['cell_number']):  #for every cell \n",
    "        for particle in set(dataframe_simulated_cell[dataframe_simulated_cell['cell_number'] == 0]['particle'] ): #for every particle\n",
    "            tmpdf = dataframe_simulated_cell[(dataframe_simulated_cell['cell_number'] == cell) & (dataframe_simulated_cell['particle'] == particle)]  #slice the dataframe\n",
    "            maxframe = np.max(tmpdf['frame'])\n",
    "            minframe = np.min(tmpdf['frame'])\n",
    "            I_g[k, 0:(maxframe+1-minframe)] = tmpdf['green_int_mean']  #fill the arrays to return out\n",
    "            x_loc[k, 0:(maxframe+1-minframe)] = tmpdf['x']\n",
    "            y_loc[k, 0:(maxframe+1-minframe)] = tmpdf['y']\n",
    "            I_g_std[k, 0:(maxframe+1-minframe)] = tmpdf['green_int_std']\n",
    "            I_r[k, 0:(maxframe+1-minframe)] = tmpdf['red_int_mean']\n",
    "            I_r_std[k, 0:(maxframe+1-minframe)] = tmpdf['red_int_std']\n",
    "            k+=1 #iterate over k (total particles)\n",
    "    return I_g, I_g_std, I_r, I_r_std, x_loc,y_loc   #return everything backout"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Reads the folder with the results and import the simulations as lists\n",
    "list_files_names = sorted([f for f in listdir(output_directory_name) if isfile(join(output_directory_name, f)) and ('.tif') in f], key=str.lower)  # reading all tif files in the folder\n",
    "list_files_names.sort(key=lambda f: int(re.sub('\\D', '', f)))  # sorting the index in numerical order\n",
    "path_files = [ str(output_directory_name.joinpath(f).resolve()) for f in list_files_names ] # creating the complete path for each file\n",
    "# Reading the microscopy data\n",
    "list_videos_original = [imread(f)[:,:,:,:] for f in  path_files] # List with all the videos\n",
    "nimg = number_of_simulated_cells"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ncrops = 4\n",
    "time_vector = np.round(np.linspace(0,simulation_time_in_sec-1,ncrops)).astype(int)\n",
    "\n",
    "#time_vector = [0, 100, 200, 300]\n",
    "ncrops = len(time_vector)\n",
    "time_vector\n",
    "channel = 1\n",
    "fig, axes = plt.subplots(nrows=1, ncols=ncrops, figsize=(7, 2))\n",
    "max_val=[]\n",
    "min_val=[]\n",
    "for i in range(0, ncrops):\n",
    "    temp_img= list_videos[0][time_vector[i],:,:,channel]\n",
    "    max_val.append(np.amax(temp_img))\n",
    "    min_val.append(np.amin(temp_img))# running the simulation\n",
    "\n",
    "for i in range(0, ncrops):\n",
    "    axes[i].imshow(list_videos[0][time_vector[i],:,:,channel],cmap='Greys_r', vmin=min(min_val), vmax=max(max_val))\n",
    "    axes[i].axis('off')\n",
    "    axes[i].set(title= str(time_vector[i]) + 's')\n",
    "name_figure = name_files+'_cells.png'\n",
    "figure_directory = str(dropbox_address.joinpath(name_figure ) )\n",
    "\n",
    "plt.tight_layout() \n",
    "plt.subplots_adjust(wspace=0.05, hspace=0)\n",
    "plt.savefig(figure_directory, transparent=True,dpi=300, bbox_inches = \"tight\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Extracting the number of real simulations from folder name\n",
    "file_name = str(output_directory_name.joinpath('sim_cell_'+str(0)+'_df.csv'))\n",
    "df_intensities_real = pd.read_csv(file_name)  \n",
    "I_g, I_g_std, I_r, I_r_std, x_loc,y_loc = df_to_array(df_intensities_real)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "selected_channel =1\n",
    "selected_masks = rsp.Cellpose(list_videos[0][0,:,:,selected_channel], num_iterations = 10, selection_method = 'max_area', diameter = 220 ).calculate_masks() # options are 'max_area' or 'max_cells'\n",
    "selected_mask  = rsp.CellposeSelection(selected_masks, list_videos[0], selection_method = mask_selection_method, particle_size = particle_size, selected_channel = selected_channel).select_mask()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig_size = (2.5, 2.5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.figure(figsize=fig_size,dpi=300)\n",
    "selected_timePoint = 0\n",
    "channel = 1\n",
    "plt.imshow(empty_videos[selected_timePoint,:,:,channel],cmap='Greys_r')\n",
    "plt.axis('off')\n",
    "name_figure = name_files+'_CELL_empty.png'\n",
    "figure_directory = str(dropbox_address.joinpath(name_figure ) )\n",
    "plt.tight_layout() \n",
    "plt.savefig(figure_directory, transparent=True,dpi=300, bbox_inches = \"tight\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.figure(figsize=fig_size,dpi=300)\n",
    "selected_timePoint = 0\n",
    "channel = 1\n",
    "plt.imshow(list_videos[0][selected_timePoint,:,:,channel],cmap='Greys_r')\n",
    "plt.axis('off')\n",
    "name_figure = name_files+'_CELL_simulated.png'\n",
    "figure_directory = str(dropbox_address.joinpath(name_figure ) )\n",
    "plt.tight_layout() \n",
    "plt.savefig(figure_directory, transparent=True,dpi=300, bbox_inches = \"tight\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plotting individual trajectories history. \n",
    "plt.figure(figsize=fig_size,dpi=300)\n",
    "selected_timePoint = 0\n",
    "channel = 1\n",
    "plt.imshow(list_videos[0][selected_timePoint,:,:,channel],cmap='Greys_r')\n",
    "plt.axis('off')\n",
    "for i in range(0, x_loc.shape[0]):  # this loop iterated for each trajectory. This is achieved by using the total number of rows in x_loc, using this: ==> \"x_loc.shape[0]\"\n",
    "  plt.plot(x_loc[i,:],y_loc[i,:], '-',linewidth = 0.5 , color = 'r')  # Then we plot the complete trajectory for each particle.\n",
    "  plt.plot(x_loc[i,0],y_loc[i,0], marker='o',markersize = 1 , color = 'y')  # Then we plot the complete trajectory for each particle.\n",
    "contuour_position = find_contours(selected_mask[:, :], 0.8)\n",
    "plt.fill(contuour_position[0][:, 1], contuour_position[0][:, 0], facecolor = 'none', edgecolor = 'yellow') # mask nucleus\n",
    "name_figure = name_files+'_CELL_trajectories.png'\n",
    "figure_directory = str(dropbox_address.joinpath(name_figure ) )\n",
    "plt.tight_layout() \n",
    "plt.savefig(figure_directory, transparent=True,dpi=300, bbox_inches = \"tight\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plotting individual trajectories history. \n",
    "empty_matrix = np.zeros_like(list_videos[0][selected_timePoint,:,:,channel])\n",
    "empty_matrix = empty_matrix+1\n",
    "plt.figure(figsize=fig_size,dpi=300)\n",
    "selected_timePoint = 0\n",
    "channel = 1\n",
    "plt.imshow(empty_matrix,cmap='Greys_r')\n",
    "plt.axis('off')\n",
    "for i in range(0, x_loc.shape[0]):  # this loop iterated for each trajectory. This is achieved by using the total number of rows in x_loc, using this: ==> \"x_loc.shape[0]\"\n",
    "  #plt.plot(x_loc[i,:],y_loc[i,:], '-',linewidth = 0.5 , color = 'orangered')  \n",
    "  plt.plot(x_loc[i,0],y_loc[i,0], marker='o',markersize = 1 , color = 'orangered')  \n",
    "contuour_position = find_contours(selected_mask[:, :], 0.8)\n",
    "plt.fill(contuour_position[0][:, 1], contuour_position[0][:, 0], facecolor = 'none', edgecolor = 'orangered') # mask nucleus\n",
    "name_figure = name_files+'_CELL_skeleton.png'\n",
    "figure_directory = str(dropbox_address.joinpath(name_figure ) )\n",
    "plt.tight_layout() \n",
    "plt.savefig(figure_directory, transparent=True,dpi=300, bbox_inches = \"tight\")\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plotting intensity distributions"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#import matplotlib as mpl\n",
    "label_size = 5\n",
    "plt.style.use('ggplot') #ggplot  #default\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['lines.linewidth'] = 1\n",
    "plt.rcParams['axes.linewidth'] = 1.5\n",
    "plt.rcParams['axes.grid'] = True\n",
    "\n",
    "mpl.rcParams['xtick.labelsize'] = label_size \n",
    "mpl.rcParams['ytick.labelsize'] = label_size \n",
    "mpl.rcParams['axes.linewidth'] = 0.5"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig_size = (8, 1)\n",
    "label_size = 8\n",
    "plt.figure(figsize=fig_size,dpi=300)\n",
    "plt.plot(I_g.T,'green',alpha=.08)\n",
    "plt.plot(np.mean(I_g.T,axis=1), linewidth =3,color='orangered')\n",
    "plt.xlabel('time [s]', size=label_size)\n",
    "plt.ylabel('Intensity [au]', size=label_size)\n",
    "plt.xlim((-1,simulation_time_in_sec))\n",
    "#plt.legend( )\n",
    "name_figure = name_files+'_image_trj.png'\n",
    "figure_directory = str(dropbox_address.joinpath(name_figure ) )\n",
    "plt.savefig(figure_directory, transparent=False,dpi=300, bbox_inches = \"tight\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Simulations for a single trajectory"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# running the simulation\n",
    "start = timer()\n",
    "output_directory_name, simulated_trajectories_ch0, simulated_trajectories_ch1, simulated_trajectories_ch2, empty_videos = fun_simulated_cells(current_dir,video_dir,ke=elongation_rate, ki=initiation_rate,trajectories_dir=None,gene_file= gene_file, number_of_simulated_cells=1,number_spots_per_cell=1,simulation_time_in_sec =simulation_time_in_sec,step_size_in_sec=1,particle_size=particle_size, diffusion_coefficient=diffusion_coefficient ,path_to_rSNAPsim= None,intensity_calculation_method=intensity_calculation_method,frame_selection_empty_video=frame_selection_empty_video,perturbation_time_start=perturbation_time_start,perturbation_time_stop=perturbation_time_stop,use_Harringtonin=use_Harringtonin,use_FRAP=use_FRAP)\n",
    "end = timer()\n",
    "print('Time to generate simulated data:',round(end - start), ' sec')\n",
    "print(output_directory_name)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Reads the folder with the results and import the simulations as lists\n",
    "list_files_names = sorted([f for f in listdir(output_directory_name) if isfile(join(output_directory_name, f)) and ('.tif') in f], key=str.lower)  # reading all tif files in the folder\n",
    "list_files_names.sort(key=lambda f: int(re.sub('\\D', '', f)))  # sorting the index in numerical order\n",
    "path_files = [ str(output_directory_name.joinpath(f).resolve()) for f in list_files_names ] # creating the complete path for each file\n",
    "# Reading the microscopy data\n",
    "list_videos_crops = [imread(f)[:,:,:,:] for f in  path_files] # List with all the videos\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.figure(figsize=(8,0.7),dpi=300)\n",
    "selected_trajectory = 0\n",
    "plt.plot(simulated_trajectories_ch1[selected_trajectory,:],color='orangered')\n",
    "name_figure = name_files+'_SSA.png'\n",
    "figure_directory = str(dropbox_address.joinpath(name_figure ) )\n",
    "plt.ylabel('SSA [ump]', fontsize=6)\n",
    "plt.xlabel('time [s]', fontsize=6)\n",
    "plt.xlim((-1,simulation_time_in_sec))\n",
    "plt.savefig(figure_directory, transparent=False,dpi=300, bbox_inches = \"tight\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "file_name = str(output_directory_name.joinpath('sim_cell_0_df.csv'))\n",
    "df_intensities_real = pd.read_csv(file_name)  \n",
    "intensity_values_in_image_trajectory = df_intensities_real[df_intensities_real['particle'] ==selected_trajectory].green_int_mean.values\n",
    "plt.figure(figsize=(8,0.7),dpi=300)\n",
    "plt.plot(intensity_values_in_image_trajectory,color='orangered')\n",
    "name_figure = name_files+'_SSA_in_cell.png'\n",
    "figure_directory = str(dropbox_address.joinpath(name_figure ) )\n",
    "plt.ylabel('Intensity [au]', fontsize=6)\n",
    "plt.xlabel('time [s]', fontsize=6)\n",
    "plt.xlim((-1,simulation_time_in_sec))\n",
    "plt.savefig(figure_directory, transparent=False,dpi=300, bbox_inches = \"tight\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ncrops = 30\n",
    "print('Time to generate simulated data:',round(end - start), ' sec')\n",
    "time_vector = np.round(np.linspace(0,simulation_time_in_sec-1,ncrops)).astype(int)\n",
    "time_vector"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "file_name = str(output_directory_name.joinpath('sim_cell_0_df.csv'))\n",
    "df_intensities_real = pd.read_csv(file_name)  "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "I_g, I_g_std, I_r, I_r_std, x_loc,y_loc = df_to_array(df_intensities_real)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# plotting\n",
    "channel = 0\n",
    "fig, axes = plt.subplots(nrows=1, ncols=ncrops, figsize=(7, 0.5))\n",
    "disk_size = 5\n",
    "max_val=[]\n",
    "min_val=[]\n",
    "for i in range(0, ncrops):\n",
    "    y_pos = y_loc[0, time_vector[i]].astype(int)\n",
    "    x_pos = x_loc[0,time_vector[i] ].astype(int)\n",
    "    crop_img= list_videos_crops[0][time_vector[i], y_pos-(disk_size): y_pos+(disk_size+1) , x_pos-(disk_size):x_pos+(disk_size+1),  channel ] \n",
    "    max_val.append(np.amax(crop_img))\n",
    "    min_val.append(np.amin(crop_img))\n",
    "\n",
    "for i in range(0, ncrops):\n",
    "    y_pos = y_loc[0, time_vector[i]].astype(int)\n",
    "    x_pos = x_loc[0,time_vector[i] ].astype(int)\n",
    "    crop_img= list_videos_crops[0][time_vector[i], y_pos-(disk_size): y_pos+(disk_size+1) , x_pos-(disk_size):x_pos+(disk_size+1),  channel ] \n",
    "    axes[i].imshow(crop_img,cmap='Greys_r', vmin=min(min_val), vmax=max(max_val))\n",
    "    axes[i].axis('off')\n",
    "name_figure = name_files+'_crops.png'\n",
    "figure_directory = str(dropbox_address.joinpath(name_figure ) )\n",
    "plt.tight_layout() \n",
    "plt.subplots_adjust(wspace=0.1, hspace=0)\n",
    "plt.savefig(figure_directory, transparent=True,dpi=300)\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b6f9c0120f6b292dd79c34d0191dad80e424033e9385d2e7f334399080b40eb3"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.13 64-bit ('FISH_processing': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}